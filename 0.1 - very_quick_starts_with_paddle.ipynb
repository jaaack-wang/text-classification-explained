{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d66c03d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Zhengxiang (Jack) Wang \n",
    "# Date: 2022-01-19\n",
    "# GitHub: https://github.com/jaaack-wang "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8f1d58",
   "metadata": {},
   "source": [
    "## Get paddle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "158e3770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python3 -m pip install paddlepaddle\n",
    "# #pip3 install paddlepaddle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c36182d",
   "metadata": {},
   "source": [
    "## Preprocess and numericalize text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21ecb647",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/w9/d_nplhzj4qx35xxlgljgdtjh0000gn/T/jieba.cache\n",
      "Loading model cost 0.995 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two vocabulary dictionaries have been built!\n",
      "Please call \u001b[1mX.vocab_to_idx | X.idx_to_vocab\u001b[0m to find out more where [X] stands for the name you used for this TextVectorizer class.\n"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "import jieba  # ---> tokenizer for Chinese\n",
    "\n",
    "# ---- load dataset ----\n",
    "train, dev, test = load_dataset(['train.tsv', 'dev.tsv', 'test.tsv'])\n",
    "\n",
    "# ---- numericalize the train set ----\n",
    "V = TextVectorizer(jieba.lcut) \n",
    "text = gather_text(train) # for collecting texts from train set\n",
    "V.build_vocab(text) # for building mapping vocab_to_idx dictionary and text_encoder\n",
    "\n",
    "train_encoded = list(encode_dataset(train, encoder=V)) # encodoing train set\n",
    "dev_encoded = list(encode_dataset(dev, encoder=V)) # encodoing dev set for validation\n",
    "test_encoded  = list(encode_dataset(test, encoder=V)) # encodoing dev set for prediction\n",
    "\n",
    "# ---- build mini batches for the train and dev set ----\n",
    "train_batched = build_batches(train_encoded, batch_size=64, \n",
    "                              max_seq_len=128, include_seq_len=False)\n",
    "\n",
    "dev_batched = build_batches(dev_encoded, batch_size=64, \n",
    "                            max_seq_len=128, include_seq_len=False)\n",
    "\n",
    "test_batched = build_batches(test_encoded, batch_size=64, \n",
    "                             max_seq_len=128, include_seq_len=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43526e6",
   "metadata": {},
   "source": [
    "## Training and evaluating models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0456585",
   "metadata": {},
   "outputs": [],
   "source": [
    "import paddle \n",
    "\n",
    "def get_model(model):\n",
    "    model = paddle.Model(model)\n",
    "    optimizer = paddle.optimizer.Adam(\n",
    "    parameters=model.parameters(), learning_rate=5e-4)\n",
    "    criterion = paddle.nn.CrossEntropyLoss()\n",
    "    metric = paddle.metric.Accuracy()\n",
    "    model.prepare(optimizer, criterion, metric)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189599b8",
   "metadata": {},
   "source": [
    "## BoW (Bag of Words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b941eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from paddle_models.BoW import BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d82063f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss value printed in the log is the current step, and the metric is the average value of previous steps.\n",
      "Epoch 1/5\n",
      "\r",
      "step 10/63 [===>..........................] - loss: 0.6363 - acc: 0.6109 - ETA: 0s - 15ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/paddle/fluid/layers/utils.py:77: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n",
      "  return (isinstance(seq, collections.Sequence) and\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 63/63 [==============================] - loss: 0.4484 - acc: 0.7960 - 13ms/step          \n",
      "Eval begin...\n",
      "step 19/19 [==============================] - loss: 0.3698 - acc: 0.8600 - 3ms/step          \n",
      "Eval samples: 1200\n",
      "Epoch 2/5\n",
      "step 63/63 [==============================] - loss: 0.1533 - acc: 0.9490 - 11ms/step          \n",
      "Eval begin...\n",
      "step 19/19 [==============================] - loss: 0.2631 - acc: 0.8700 - 3ms/step          \n",
      "Eval samples: 1200\n",
      "Epoch 3/5\n",
      "step 63/63 [==============================] - loss: 0.0313 - acc: 0.9808 - 12ms/step          \n",
      "Eval begin...\n",
      "step 19/19 [==============================] - loss: 0.2298 - acc: 0.8667 - 3ms/step          \n",
      "Eval samples: 1200\n",
      "Epoch 4/5\n",
      "step 63/63 [==============================] - loss: 0.0145 - acc: 0.9918 - 11ms/step          \n",
      "Eval begin...\n",
      "step 19/19 [==============================] - loss: 0.2083 - acc: 0.8700 - 3ms/step          \n",
      "Eval samples: 1200\n",
      "Epoch 5/5\n",
      "step 63/63 [==============================] - loss: 0.0064 - acc: 0.9945 - 11ms/step          \n",
      "Eval begin...\n",
      "step 19/19 [==============================] - loss: 0.1977 - acc: 0.8575 - 3ms/step          \n",
      "Eval samples: 1200\n",
      "CPU times: user 3.82 s, sys: 94.7 ms, total: 3.91 s\n",
      "Wall time: 3.98 s\n"
     ]
    }
   ],
   "source": [
    "model = BoW(len(V.vocab_to_idx), 2)\n",
    "model = get_model(model)\n",
    "%time model.fit(train_batched, dev_batched, epochs=5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1cf40ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval begin...\n",
      "step 10/19 - loss: 0.2706 - acc: 0.8922 - 3ms/step\n",
      "step 19/19 - loss: 0.3059 - acc: 0.8775 - 3ms/step\n",
      "Eval samples: 1200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': [0.30594957], 'acc': 0.8775}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_batched)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c1ac14",
   "metadata": {},
   "source": [
    "## CNN (Convolutional Neural Network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "253bf7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from paddle_models.CNN import CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06dc6b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss value printed in the log is the current step, and the metric is the average value of previous steps.\n",
      "Epoch 1/5\n",
      "step 63/63 [==============================] - loss: 0.5883 - acc: 0.6680 - 170ms/step          \n",
      "Eval begin...\n",
      "step 19/19 [==============================] - loss: 0.5990 - acc: 0.7792 - 59ms/step          \n",
      "Eval samples: 1200\n",
      "Epoch 2/5\n",
      "step 63/63 [==============================] - loss: 0.2585 - acc: 0.8340 - 168ms/step          \n",
      "Eval begin...\n",
      "step 19/19 [==============================] - loss: 0.3046 - acc: 0.8617 - 60ms/step          \n",
      "Eval samples: 1200\n",
      "Epoch 3/5\n",
      "step 63/63 [==============================] - loss: 0.0795 - acc: 0.9430 - 164ms/step          \n",
      "Eval begin...\n",
      "step 19/19 [==============================] - loss: 0.1628 - acc: 0.8783 - 60ms/step          \n",
      "Eval samples: 1200\n",
      "Epoch 4/5\n",
      "step 63/63 [==============================] - loss: 0.0202 - acc: 0.9845 - 172ms/step          \n",
      "Eval begin...\n",
      "step 19/19 [==============================] - loss: 0.1093 - acc: 0.8742 - 58ms/step          \n",
      "Eval samples: 1200\n",
      "Epoch 5/5\n",
      "step 63/63 [==============================] - loss: 0.0064 - acc: 0.9955 - 168ms/step          \n",
      "Eval begin...\n",
      "step 19/19 [==============================] - loss: 0.0979 - acc: 0.8750 - 59ms/step          \n",
      "Eval samples: 1200\n",
      "CPU times: user 57.1 s, sys: 683 ms, total: 57.8 s\n",
      "Wall time: 58.7 s\n"
     ]
    }
   ],
   "source": [
    "model = CNN(len(V.vocab_to_idx), 2)\n",
    "model = get_model(model)\n",
    "%time model.fit(train_batched, dev_batched, epochs=5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6662c522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval begin...\n",
      "step 10/19 - loss: 0.3241 - acc: 0.9078 - 61ms/step\n",
      "step 19/19 - loss: 0.3437 - acc: 0.8892 - 59ms/step\n",
      "Eval samples: 1200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': [0.34374633], 'acc': 0.8891666666666667}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_batched)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5be71b6",
   "metadata": {},
   "source": [
    "## RNN (Recurrent neural network)\n",
    "\n",
    "As the RNN models also take as an input the sequence length, we need to re-encode the train set, dev set, and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fbf96ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- build mini batches for the train and dev set ----\n",
    "train_batched = build_batches(train_encoded, batch_size=64, \n",
    "                              max_seq_len=128, include_seq_len=True)\n",
    "\n",
    "dev_batched = build_batches(dev_encoded, batch_size=64, \n",
    "                            max_seq_len=128, include_seq_len=True)\n",
    "\n",
    "test_batched = build_batches(test_encoded, batch_size=64, \n",
    "                             max_seq_len=128, include_seq_len=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fae1917",
   "metadata": {},
   "source": [
    "## SimpleRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a8982c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from paddle_models.S_RNN import SimpleRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb94e7ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss value printed in the log is the current step, and the metric is the average value of previous steps.\n",
      "Epoch 1/5\n",
      "step 63/63 [==============================] - loss: 0.6822 - acc: 0.5500 - 90ms/step          \n",
      "Eval begin...\n",
      "step 19/19 [==============================] - loss: 0.6384 - acc: 0.6642 - 33ms/step          \n",
      "Eval samples: 1200\n",
      "Epoch 2/5\n",
      "step 63/63 [==============================] - loss: 0.3788 - acc: 0.8110 - 92ms/step          \n",
      "Eval begin...\n",
      "step 19/19 [==============================] - loss: 0.4491 - acc: 0.8108 - 32ms/step          \n",
      "Eval samples: 1200\n",
      "Epoch 3/5\n",
      "step 63/63 [==============================] - loss: 0.0111 - acc: 0.9575 - 92ms/step          \n",
      "Eval begin...\n",
      "step 19/19 [==============================] - loss: 0.6173 - acc: 0.7667 - 33ms/step          \n",
      "Eval samples: 1200\n",
      "Epoch 4/5\n",
      "step 63/63 [==============================] - loss: 0.0062 - acc: 0.9910 - 93ms/step          \n",
      "Eval begin...\n",
      "step 19/19 [==============================] - loss: 0.6760 - acc: 0.7933 - 33ms/step          \n",
      "Eval samples: 1200\n",
      "Epoch 5/5\n",
      "step 63/63 [==============================] - loss: 0.0024 - acc: 0.9958 - 94ms/step          \n",
      "Eval begin...\n",
      "step 19/19 [==============================] - loss: 0.6164 - acc: 0.7967 - 39ms/step          \n",
      "Eval samples: 1200\n",
      "CPU times: user 31.3 s, sys: 555 ms, total: 31.8 s\n",
      "Wall time: 32.3 s\n"
     ]
    }
   ],
   "source": [
    "model = SimpleRNN(len(V.vocab_to_idx), 2, bidirectional=True)\n",
    "model = get_model(model)\n",
    "%time model.fit(train_batched, dev_batched, epochs=5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "559135a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval begin...\n",
      "step 10/19 - loss: 0.5750 - acc: 0.7734 - 41ms/step\n",
      "step 19/19 - loss: 0.4688 - acc: 0.7792 - 41ms/step\n",
      "Eval samples: 1200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': [0.46877885], 'acc': 0.7791666666666667}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_batched)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2fad34",
   "metadata": {},
   "source": [
    "## LSTM (Long short-term memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "51e4e250",
   "metadata": {},
   "outputs": [],
   "source": [
    "from paddle_models.LSTM import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ebaa36e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss value printed in the log is the current step, and the metric is the average value of previous steps.\n",
      "Epoch 1/5\n",
      "step 63/63 [==============================] - loss: 0.6460 - acc: 0.5835 - 313ms/step          \n",
      "Eval begin...\n",
      "step 19/19 [==============================] - loss: 0.5947 - acc: 0.7575 - 119ms/step          \n",
      "Eval samples: 1200\n",
      "Epoch 2/5\n",
      "step 63/63 [==============================] - loss: 0.2090 - acc: 0.8700 - 314ms/step          \n",
      "Eval begin...\n",
      "step 19/19 [==============================] - loss: 0.3687 - acc: 0.8783 - 112ms/step          \n",
      "Eval samples: 1200\n",
      "Epoch 3/5\n",
      "step 63/63 [==============================] - loss: 0.0069 - acc: 0.9607 - 286ms/step          \n",
      "Eval begin...\n",
      "step 19/19 [==============================] - loss: 0.4390 - acc: 0.8633 - 105ms/step          \n",
      "Eval samples: 1200\n",
      "Epoch 4/5\n",
      "step 63/63 [==============================] - loss: 0.0186 - acc: 0.9875 - 280ms/step          \n",
      "Eval begin...\n",
      "step 19/19 [==============================] - loss: 0.3644 - acc: 0.8467 - 104ms/step          \n",
      "Eval samples: 1200\n",
      "Epoch 5/5\n",
      "step 63/63 [==============================] - loss: 0.0013 - acc: 0.9940 - 285ms/step          \n",
      "Eval begin...\n",
      "step 19/19 [==============================] - loss: 0.4008 - acc: 0.8675 - 109ms/step          \n",
      "Eval samples: 1200\n",
      "CPU times: user 1min 41s, sys: 1.3 s, total: 1min 42s\n",
      "Wall time: 1min 43s\n"
     ]
    }
   ],
   "source": [
    "model = LSTM(len(V.vocab_to_idx), 2, bidirectional=True)\n",
    "model = get_model(model)\n",
    "%time model.fit(train_batched, dev_batched, epochs=5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0846a7ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval begin...\n",
      "step 10/19 - loss: 0.6178 - acc: 0.8812 - 111ms/step\n",
      "step 19/19 - loss: 0.2819 - acc: 0.8875 - 109ms/step\n",
      "Eval samples: 1200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': [0.2819071], 'acc': 0.8875}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_batched)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592f99b9",
   "metadata": {},
   "source": [
    "## GUR (Gated recurrent units) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3577037e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from paddle_models.GRU import GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eb48ef52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss value printed in the log is the current step, and the metric is the average value of previous steps.\n",
      "Epoch 1/5\n",
      "step 63/63 [==============================] - loss: 0.6723 - acc: 0.5493 - 237ms/step          \n",
      "Eval begin...\n",
      "step 19/19 [==============================] - loss: 0.6431 - acc: 0.7442 - 100ms/step          \n",
      "Eval samples: 1200\n",
      "Epoch 2/5\n",
      "step 63/63 [==============================] - loss: 0.2153 - acc: 0.8548 - 234ms/step          \n",
      "Eval begin...\n",
      "step 19/19 [==============================] - loss: 0.3313 - acc: 0.8725 - 96ms/step          \n",
      "Eval samples: 1200\n",
      "Epoch 3/5\n",
      "step 63/63 [==============================] - loss: 0.0123 - acc: 0.9635 - 231ms/step          \n",
      "Eval begin...\n",
      "step 19/19 [==============================] - loss: 0.3688 - acc: 0.8708 - 98ms/step          \n",
      "Eval samples: 1200\n",
      "Epoch 4/5\n",
      "step 63/63 [==============================] - loss: 0.0104 - acc: 0.9892 - 229ms/step          \n",
      "Eval begin...\n",
      "step 19/19 [==============================] - loss: 0.3421 - acc: 0.8675 - 91ms/step          \n",
      "Eval samples: 1200\n",
      "Epoch 5/5\n",
      "step 63/63 [==============================] - loss: 0.0018 - acc: 0.9942 - 226ms/step          \n",
      "Eval begin...\n",
      "step 19/19 [==============================] - loss: 0.3680 - acc: 0.8533 - 91ms/step          \n",
      "Eval samples: 1200\n",
      "CPU times: user 1min 19s, sys: 1.19 s, total: 1min 20s\n",
      "Wall time: 1min 21s\n"
     ]
    }
   ],
   "source": [
    "model = GRU(len(V.vocab_to_idx), 2, bidirectional=True)\n",
    "model = get_model(model)\n",
    "%time model.fit(train_batched, dev_batched, epochs=5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4cc0daa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval begin...\n",
      "step 10/19 - loss: 0.6577 - acc: 0.8719 - 96ms/step\n",
      "step 19/19 - loss: 0.2988 - acc: 0.8700 - 93ms/step\n",
      "Eval samples: 1200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': [0.2987765], 'acc': 0.87}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_batched)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
